<head>

    <style>
        #left{
            position: absolute;
            width: 50vw;
            height: 100vh;
            left: 0px;
            color: red;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #right{
            position: absolute;
            width: 50vw;
            height: 100vh;
            right: 0px;
            color: red;
            display: flex;
            justify-content: center;
            align-items: center;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<script>
    let video;

    const MODEL_WIDTH = 384;
    const MODEL_HEIGHT = 384;
    const canvas = document.createElement("canvas");
    canvas.width = MODEL_WIDTH;
    canvas.height = MODEL_HEIGHT;
    const ctx = canvas.getContext("2d");

    async function onPlay(params) {

        video = document.getElementById("inputVideo");
        
        const session = await ort.InferenceSession.create(
            "depth_anything_small.onnx",
            { executionProviders: ["webgpu"] }
        );

        setInterval(async () => {
            getInputTensor(video)
            // ...Get input tensor
            const feeds = { input: inputTensor };
            const results = await session.run(feeds);
            const depth = results.output.data;
            const centerDepth = getCenterDepth(depth, MODEL_WIDTH, MODEL_HEIGHT)
            const smoothDepth = smooth(depth)

            console.log(smoothDepth);
        }, 100);
    }

    function getCenterDepth(depth, width, height) {
        const x = Math.floor(width / 2);
        const y = Math.floor(height / 2);
        return depth[y * width + x];
    }

    let smoothedValue = 0;
    function smooth(value) {
        const alpha = 0.1;
        smoothedValue = smoothedValue * (1 - alpha) + value * alpha;
        return smoothedValue;
    }

    function getInputTensor(video) {
        // Draw video frame scaled to model size
        ctx.drawImage(video, 0, 0, MODEL_WIDTH, MODEL_HEIGHT);

        const imageData = ctx.getImageData(0, 0, MODEL_WIDTH, MODEL_HEIGHT);
        const { data } = imageData; // RGBA

        const floatData = new Float32Array(1 * 3 * MODEL_WIDTH * MODEL_HEIGHT);

        // Convert RGBA â†’ CHW format
        for (let i = 0; i < MODEL_WIDTH * MODEL_HEIGHT; i++) {
            const r = data[i * 4] / 255;
            const g = data[i * 4 + 1] / 255;
            const b = data[i * 4 + 2] / 255;

            floatData[i] = r;                                   // R channel
            floatData[i + MODEL_WIDTH * MODEL_HEIGHT] = g;       // G channel
            floatData[i + 2 * MODEL_WIDTH * MODEL_HEIGHT] = b;   // B channel
        }

        return new ort.Tensor("float32", floatData, [1, 3, MODEL_HEIGHT, MODEL_WIDTH]);
    }

    let left = 0;
    let right = 0;

    addEventListener("keydown", (event) => 
    { 
        if(event.key == "+"){
            left += 1;
            right += 1;
            document.getElementById("left").style.left = `${left}px`
            document.getElementById("right").style.right = `${right}px`
        }
        if(event.key == "-"){
            left -= 1;
            right -= 1;
            document.getElementById("left").style.left = `${left}px`
            document.getElementById("right").style.right = `${right}px`
        }
    });

</script>
<body style="background: black; margin: 0; font-family: consolas; font-size: 100px;">
    <div id="left">
        <div>
            +
        </div>
    </div>
    <div id="right">
        <div>
            +
        </div>
    </div>
    <video id="inputVideo" onplay="onPlay(this)" style="opacity: 1;" autoplay muted></video>
</body>